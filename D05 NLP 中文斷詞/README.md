# Day5 NLP 中文斷詞
* 在機器學習中是透過向量來訓練，因此要將文章轉為向量呈現，必須把文章斷為字詞來代表該文章
* 英文斷詞相對簡單，透過空格斷詞即可
* 而中文則是所有詞都串連在一起，會有下列的可能性

|句子|斷詞結果|
|-|-|
|全台大停電|全/台大/停電|
|全台大停電|全台/大/停電|
|全台大停電|全/台/大停電|

* 因此，有些方法幫助電腦學習中文斷詞

## 斷詞方法
* 斷詞的主流方法
    * 基於詞典的斷詞法：按照策略將待匹配的字串和已建立好的詞典進行匹配
    * 基於統計的機器學習算法：HMM, Conditional Random Field(CRF), SVM, etc
    * 基於深度學習的算法：雙向 LSTM 模型
* 目前主流的中文斷詞 "結巴" 是基於傳統機器學習算法的斷詞演算法

## 結巴斷詞介紹
* 結巴斷詞主要分為：
    * 針對存在於字典的字詞：
        * 根據字典產生 Trie Tree(字典樹、字首樹、前綴樹)
        * 根據 Trie Tree 建立給定輸入句的 DAG (有向無環圖)
        * 使用動態規劃 (Dynamic Programming) 來找出最大機率路徑，此路徑為基於詞頻最大的斷詞結果
    * 針對不存在於字典的字詞：
        * 使用隱馬可夫模型 (HMM) 與維特比演算法 (Viterbi) 進行斷詞辨識

### 字典樹 (Trie Tree)
* Trie Tree 基於一個字典建構，在結巴中字典為 dict.txt，內含兩萬多個詞，包含詞、詞頻、詞性 (結巴作者根據中國人民日報語料訓練)
* 當數個詞語前面的字相同 (即有相同前綴)，就可以使用 Trie Tree 來儲存

### 有向無環圖 (DAG)
* 給一個待斷詞的句子，根據由字典生成的 Trie Tree 查找來生成有向無環圖
* 根據字典查詢，列舉出根據字典所有可能的句子切分